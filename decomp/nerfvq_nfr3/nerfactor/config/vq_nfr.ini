[DEFAULT]

# ====== Must-Have ======
# These parameters are required by the pipeline, regardless of your custom code

# ------ Data ------
dataset = shape_unit
no_batch = True
# bs = 4
cache = True
data_type = nerf

# ------ Model ------
model = vq_nfr

# ------ Optimization ------
loss = l2
lr = 5e-4
lr_decay_steps = 500_000
lr_decay_rate = 0.1
clipnorm = -1
clipvalue = -1
epochs = 150

# ------ Logging and Checkpointing ------
ckpt_period = 30
vali_period = 30
vali_batches = 8
vis_train_batches = 4
keep_recent_epochs = -1
vis_view = 3

# ------ IO ------
overwrite = False
# The following two decide the output directory
outroot = /output/train/hotdog_2163_nerfactor/
xname = lr{lr}


# ====== Custom ======
# These parameters are whatever your custom dataset and model require

# ------ Data ------
data_root = /data/render_outdoor_inten3_gi/hotdog_2163/
data_nerf_root = /output/surf/hotdog_2163/
light_path = /output/brdf/hotdog_2163
unit_root = /output/brdf/hotdog_2163
cluster_center_path = /output/brdf/hotdog_2163
use_nerf_alpha = False
imh = 512
light_h = 16
near = 2
far = 6
ndc = False
white_bg = True
left_coords = False

# ------ Model ------
xyz_jitter_std = 0
smooth_use_l1 = False
l_var_weight = 0

# Shape
shape_mode = finetune
# shape_mode = frozen
shape_model_ckpt = /output/train/hotdog_2163_shape/lr1e-2/checkpoints/ckpt-2
nfr_model_ckpt = /output/train/hotdog_2163_shape/lr1e-2/checkpoints/ckpt-2
nerf_shape_respect = 0

# BRDF
albedo_slope = 1
albedo_bias = 0
pred_brdf = True

init_bias_weight = 1
default_bias_weight = 1

learned_brdf_scale = 1
normalize_z = True

# Lighting
light_init_val = 0.5
light_init_max = 1
light_init_scale = 1
env_inten = 0.8
light_tv_weight = 5e-6
light_achro_weight = 0
sg_init_path = /home/ma-user/work/zhl/pn_pro/data/mean_sgs.npy
l_chunk = 128

# Rendering
linear2srgb = True
test_envmap_dir = /data/envmaps/for-render_h16/test/

# ------ Network ------
mlp_chunk = 100000
mlp_width = 128
mlp_depth = 4
mlp_skip_at = 2
conv_width = 256

# Positional encoding
pos_enc = True
n_freqs_xyz = 10
n_freqs_ldir = 4
n_freqs_vdir = 4

enc_depth = 8
enc_skip_at = 4
enc_width = 256

# vq_layer
num_embed = 15
commitment_cost = 0.1
vq_loss_weight = 1.
num_drop = 12
thres_str = 0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65

# ours
chr_alpha = 60
chr_thres = 0.1
total_sample_vq = 200000
best_thres = 0.002
drop_thres_rate = 0
random_seed = 2

combine_weight = 0.2
mat_sloss_weight = 0.05
chromaticity_loss_weight = 1.
sim_loss_weight = 1e-4
lambert_weight = 1e-3

no_brdf_chunk = True

# ------ Misc. ------
# De facto training batch size: number of random rays per gradient step
n_rays_per_step = 1024
# File viewer prefix, if any
viewer_prefix = http://vision38.csail.mit.edu